# List of known artifact types

Note that some artifacts are executable (e.g. scripts) and some are not (e.g. tutorials). For a discussion on why we might want to divide our work in to the following areas, see the [SE research reuse manifesto](SEresearchReuseManifesto.md).

Note also that research artifacts can be _smaller_ than a research paper (i.e. one paper can contain many artifacts) or _bigger_ (e.g. a paper might use soem scripts or data)

The following list is sorted from smaller to bigger:

1. Motivational statements   or reports or challenge statements or lists of open issues that prompt an analysis;
1. Hypotheses,  about expected effects in some area;
1. Checklists used to design the analysis (see also, the [Checklist Manifesto](http://atulgawande.com/book/the-checklist-manifesto/);
1. Bibliographies, some of which might be annotated;
1. Study instruments  such as surveys interview scripts, etc;
1. Statistical tests used to analyze results;
1. Commentary on scripts used in the analysis;
1. Examples of particularly informative visualizations (e.g. Sparklines http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR )
1. Baseline results against which new work can be compared;
1. Sampling procedures e.g. ``how did you choose the projects you studied?'';
1. Patterns describing  best practices for performing this kind of analysis;
1. Anti-patterns   describing cautionary tales of ``gotchas'' to avoid when doing this kind of work;
1. Negative results  that are anti-patterns, backed up by empirical results;
1. Tutorial materials: Guides to help  newcomers become proficient in the area. Some of these tutorial materials  may be generated by the researcher and others may be collected from other sources.
1. New results   that offer guidance on how to best handle future problems.
1. Future work:  From the results, there many be speculations about open issues of future issues that might become the  motivation  for the next round of research.
1. The actual text   of an author's papers;
1. Any  data used in an analysis
    + Either  _raw_ from a project;
    + Or some _redived_ product.
   Note that some data is too large to fit into the standard on-line freely available repos (e.g. Github only allows 1GB reps). For such data, we suggest using some file `XXX.goto`; each line of which is one url where the releated data can be collected. 
1. Scripts  used to perform the analysis (the main analysis or the subsequent statistical tests or visualizations; e.g.    the  [Python Sparklines generator](https://pypi.python.org/pypi/pysparklines)). Scripts can also implement some of the patterns
  identified by the paper.
1. Executable  models that can generate exemplar data;  or which offer an executable form of current hypotheses;
1. Tools to let novices automatically rerun the analysis; e.g.
    + Config management files that can
       + build the system/ paper from raw material and/or
       + update the relevant files using some package manager
    +  Virtual machines containing all the above scripts, data, etc, pre-configured such that a newcomer can automatically run the old analysis.

 
If your artifact is not included in the above, then write an issue in this repo to propose a new artifact type.
